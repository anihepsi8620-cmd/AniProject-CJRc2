{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12694cfa",
   "metadata": {},
   "source": [
    "# Time Series Forecasting: LSTM baseline + Attention Seq2Seq\n",
    "\n",
    "This notebook is Colab-ready. Upload `electricity_consumption.csv` to `/content` (or mount Drive) before running. It performs:\n",
    "- Data loading and hourly resampling\n",
    "- Imputation with IterativeImputer\n",
    "- Baseline LSTM (48 â†’ 6 hours)\n",
    "- Attention-augmented seq2seq (Bahdanau)\n",
    "- Evaluation (RMSE, MAE, MAPE)\n",
    "- Saves models and run summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe4a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup imports\n",
    "import os, json, math, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"Libraries loaded. TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d24f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration: set path where you uploaded the CSV\n",
    "POSSIBLE_PATHS = [\n",
    "    '/content/electricity_consumption.csv',\n",
    "    '/mnt/data/electricity_consumption.csv',\n",
    "    './electricity_consumption.csv'\n",
    "]\n",
    "DATA_PATH = None\n",
    "for p in POSSIBLE_PATHS:\n",
    "    if Path(p).exists():\n",
    "        DATA_PATH = p\n",
    "        break\n",
    "if DATA_PATH is None:\n",
    "    raise FileNotFoundError(\"Place electricity_consumption.csv in /content or update DATA_PATH.\")\n",
    "print(\"Using:\", DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc9470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV and detect datetime column\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "display(df.head())\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# detect datetime column\n",
    "datetime_col = None\n",
    "for c in df.columns:\n",
    "    if 'date' in c.lower() or 'time' in c.lower() or 'timestamp' in c.lower():\n",
    "        datetime_col = c\n",
    "        break\n",
    "if datetime_col is None:\n",
    "    for c in df.columns[:3]:\n",
    "        try:\n",
    "            pd.to_datetime(df[c])\n",
    "            datetime_col = c\n",
    "            break\n",
    "        except Exception:\n",
    "            continue\n",
    "if datetime_col is None:\n",
    "    raise ValueError(\"Couldn't auto-detect datetime column. Rename it to include 'date' or 'time' or make it the first columns.\")\n",
    "print('Datetime column:', datetime_col)\n",
    "df[datetime_col] = pd.to_datetime(df[datetime_col])\n",
    "df = df.set_index(datetime_col).sort_index()\n",
    "print('Index range:', df.index.min(), 'to', df.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f11722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample hourly and impute missing values\n",
    "df_hour = df.resample('H').mean()\n",
    "numeric_cols = df_hour.select_dtypes(include=['float64','int64']).columns.tolist()\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "imputer = IterativeImputer(random_state=0, max_iter=10)\n",
    "df_hour[numeric_cols] = imputer.fit_transform(df_hour[numeric_cols])\n",
    "df_hour = df_hour.ffill().bfill()\n",
    "display(df_hour.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb803e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose target column (heuristic) and features\n",
    "target_candidates = [c for c in numeric_cols if any(k in c.lower() for k in ['consum','global_active','active_power','power'])]\n",
    "TARGET = target_candidates[0] if target_candidates else numeric_cols[0]\n",
    "print(\"Target:\", TARGET)\n",
    "FEATURES = [c for c in numeric_cols if c != TARGET]\n",
    "print(\"Features:\", FEATURES)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_all = df_hour[FEATURES].values if FEATURES else df_hour[[TARGET]].values\n",
    "y_all = df_hour[[TARGET]].values\n",
    "X_scaled = scaler_X.fit_transform(X_all)\n",
    "y_scaled = scaler_y.fit_transform(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d3894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences (48 -> 6) and time-aware split\n",
    "def create_sequences(X, y, input_steps=48, output_steps=6):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - input_steps - output_steps + 1):\n",
    "        Xs.append(X[i:(i+input_steps)])\n",
    "        ys.append(y[(i+input_steps):(i+input_steps+output_steps)].reshape(-1))\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "INPUT_STEPS = 48\n",
    "OUTPUT_STEPS = 6\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, INPUT_STEPS, OUTPUT_STEPS)\n",
    "print(\"Seq shapes:\", X_seq.shape, y_seq.shape)\n",
    "\n",
    "train_size = int(len(X_seq) * 0.7)\n",
    "val_size = int(len(X_seq) * 0.15)\n",
    "X_train = X_seq[:train_size]; y_train = y_seq[:train_size]\n",
    "X_val = X_seq[train_size:train_size+val_size]; y_val = y_seq[train_size:train_size+val_size]\n",
    "X_test = X_seq[train_size+val_size:]; y_test = y_seq[train_size+val_size:]\n",
    "print('Train/Val/Test:', len(X_train), len(X_val), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e425890",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Mas# Baseline LSTM model\n",
    "def build_lstm_baseline(input_shape, output_steps):king()(inputs)\n",
    "    x = layers.LSTM(128, return_sequences=False)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(output_steps)(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "lstm_model = build_lstm_baseline((INPUT_STEPS, X_train.shape[2]), OUTPUT_STEPS)\n",
    "lstm_model.summary()\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history_lstm = lstm_model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val,y_val), callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb56b9f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bahdanau attention and seq2seq (simplified)\n",
    "class BahdanauAttention(layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = layers.Dense(units)\n",
    "        self.W2 = layers.Dense(units)\n",
    "        self.V = layers.Dense(1)\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(query_with_time_axis)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, tf.squeeze(attention_weights, -1)\n",
    "\n",
    "def build_attention_seq2seq(input_shape, output_steps, enc_units=128, dec_units=128):\n",
    "    encoder_inputs = layers.Input(shape=input_shape, name='encoder_inputs')\n",
    "    encoder_mask = layers.Masking()(encoder_inputs)\n",
    "    encoder_lstm = layers.LSTM(enc_units, return_sequences=True, return_state=True, name='encoder_lstm')\n",
    "    enc_outputs, enc_h, enc_c = encoder_lstm(encoder_mask)\n",
    "    decoder_inputs = layers.Input(shape=(output_steps, input_shape[1]), name='decoder_inputs')\n",
    "    attention = BahdanauAttention(dec_units)\n",
    "    decoder_lstm_cell = layers.LSTMCell(dec_units)\n",
    "    dense_out = layers.Dense(1)\n",
    "    all_outputs = []\n",
    "    state_h = enc_h; state_c = enc_c\n",
    "    last_encoder_step = encoder_inputs[:, -1, :]\n",
    "    decoder_input_t = tf.expand_dims(last_encoder_step, 1)\n",
    "    for t in range(output_steps):\n",
    "        context_vec, attn_weights = attention(state_h, enc_outputs)\n",
    "        decoder_input_flat = tf.concat([tf.squeeze(decoder_input_t,1), context_vec], axis=-1)\n",
    "        out, [state_h, state_c] = decoder_lstm_cell(decoder_input_flat, states=[state_h, state_c])\n",
    "        output = dense_out(out)\n",
    "        all_outputs.append(output)\n",
    "        decoder_input_t = tf.expand_dims(tf.tile(output, [1, input_shape[1]]), 1)\n",
    "    decoder_outputs = layers.Lambda(lambda x: K.stack(x, axis=1))(all_outputs)\n",
    "    decoder_outputs = layers.Reshape((output_steps,))(decoder_outputs)\n",
    "    model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "decoder_dummy = np.zeros((X_train.shape[0], OUTPUT_STEPS, X_train.shape[2]))\n",
    "attn_model = build_attention_seq2seq((INPUT_STEPS, X_train.shape[2]), OUTPUT_STEPS)\n",
    "attn_model.summary()\n",
    "history_attn = attn_model.fit([X_train, decoder_dummy], y_train, epochs=30, batch_size=32, validation_data=([X_val, np.zeros((X_val.shape[0], OUTPUT_STEPS, X_val.shape[2]))], y_val), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation helpers and metrics\n",
    "def inverse_and_metrics(y_true_scaled, y_pred_scaled):\n",
    "    y_true = scaler_y.inverse_transform(y_true_scaled.reshape(-1,1)).reshape(y_true_scaled.shape)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1,1)).reshape(y_pred_scaled.shape)\n",
    "    rmse = math.sqrt(mean_squared_error(y_true.flatten(), y_pred.flatten()))\n",
    "    mae = mean_absolute_error(y_true.flatten(), y_pred.flatten())\n",
    "    mape = np.mean(np.abs((y_true.flatten() - y_pred.flatten()) / (y_true.flatten()+1e-9))) * 100\n",
    "    return rmse, mae, mape, y_true, y_pred\n",
    "\n",
    "y_pred_lstm = lstm_model.predict(X_test)\n",
    "rmse_lstm, mae_lstm, mape_lstm, y_true, y_pred_lstm_inv = inverse_and_metrics(y_test, y_pred_lstm)\n",
    "print('LSTM -> RMSE: {:.4f}, MAE: {:.4f}, MAPE: {:.2f}%'.format(rmse_lstm, mae_lstm, mape_lstm))\n",
    "\n",
    "decoder_dummy_test = np.zeros((X_test.shape[0], OUTPUT_STEPS, X_test.shape[2]))\n",
    "y_pred_attn = attn_model.predict([X_test, decoder_dummy_test])\n",
    "rmse_attn, mae_attn, mape_attn, _, y_pred_attn_inv = inverse_and_metrics(y_test, y_pred_attn)\n",
    "print('Attn -> RMSE: {:.4f}, MAE: {:.4f}, MAPE: {:.2f}%'.format(rmse_attn, mae_attn, mape_attn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2629df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot example predictions\n",
    "def plot_preds(y_true, y_pred, idx=0):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(y_true[idx], marker='o', label='True')\n",
    "    plt.plot(y_pred[idx], marker='x', label='Pred')\n",
    "    plt.title('Example multi-step forecast (true vs pred)')\n",
    "    plt.xlabel('Horizon (hours)'); plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "plot_preds(scaler_y.inverse_transform(y_test.reshape(-1,1)).reshape(y_test.shape), y_pred_lstm_inv, idx=0)\n",
    "plot_preds(scaler_y.inverse_transform(y_test.reshape(-1,1)).reshape(y_test.shape), y_pred_attn_inv, idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c3714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models and summary to /content/project_output\n",
    "OUTPUT_DIR = '/content/project_output'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "lstm_model.save(os.path.join(OUTPUT_DIR, 'lstm_baseline.h5'))\n",
    "attn_model.save(os.path.join(OUTPUT_DIR, 'attn_seq2seq.h5'))\n",
    "\n",
    "summary = {\n",
    "    'target': TARGET,\n",
    "    'input_steps': INPUT_STEPS,\n",
    "    'output_steps': OUTPUT_STEPS,\n",
    "    'lstm_metrics': {'rmse': float(rmse_lstm), 'mae': float(mae_lstm), 'mape': float(mape_lstm)},\n",
    "    'attn_metrics': {'rmse': float(rmse_attn), 'mae': float(mae_attn), 'mape': float(mape_attn)}\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, 'run_summary.json'),'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print('Saved to', OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
